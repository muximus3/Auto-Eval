# Auto-Eval

åˆ©ç”¨ ChatGPTï¼ˆGPT-3.5-turboï¼‰ã€GPT-4 å’Œ Claude çš„ APIï¼Œåªéœ€ä¸€è¡Œå‘½ä»¤å°±å¯ä»¥å¯¹æˆ‘ä»¬è®­ç»ƒçš„è¯­è¨€æ¨¡å‹è¿›è¡Œ**è‡ªåŠ¨è¯„ä¼°** ã€‚

è¯„ä¼°æç¤ºè¯ç»è¿‡å¹¿æ³›çš„æµ‹è¯•ï¼Œä»¥æœ€å¤§é™åº¦åœ°ç¡®ä¿è¯„ä¼°çš„å‡†ç¡®æ€§ï¼ˆå³ä½¿ä½¿ç”¨GPT-3.5ï¼‰ï¼ŒåŒæ—¶æœ€å°åŒ–å•è¯æ•°é‡ä»¥èŠ‚çœå­—ç¬¦é¢„ç®—ï¼Œå› ä¸º GPT-4 éå¸¸è´µ ğŸ’°ã€‚

å¦‚æœæƒ³è‡ªå®šä¹‰è¯„ä¼°æç¤ºï¼Œæ‚¨å¯ä»¥ä½¿ç”¨é»˜è®¤æ¨¡æ¿ä½œä¸ºåŸºç¡€è¿›è¡Œä¿®æ”¹ã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…ä¸‹é¢æä¾›çš„æ–‡æ¡£([ç‚¹å‡»è¿™é‡Œ](#jump))ã€‚

## åŸç†ï¼Ÿ

å‡è®¾æˆ‘ä»¬å·²ç»æœ‰ä¸€ä¸ªæµ‹è¯•é›†ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸åŒç‰ˆæœ¬æ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼Œå¹¶å°†é¢„æµ‹ç»“æœä¿å­˜åœ¨è¯¸å¦‚ JSONã€CSVã€Excel ç­‰æ ¼å¼çš„æ–‡ä»¶æ ¼å¼ä¸­ã€‚è¾“å‡ºæ–‡ä»¶çš„ç»“æ„å¦‚ä¸‹æ‰€ç¤ºï¼š

| prompt | output | model | category |
| --- | --- | --- | --- |
| 1+1 ç­‰äºå¤šå°‘ï¼Ÿ | 3 | model_a | ç®—æœ¯ |
| æ³•å›½çš„é¦–éƒ½æ˜¯å“ªé‡Œï¼Ÿ | å·´é» | model_a | å¸¸è¯† |
| 1+1 ç­‰äºå¤šå°‘ï¼Ÿ | 2 | model_b | ç®—æœ¯ |
| æ³•å›½çš„é¦–éƒ½æ˜¯å“ªé‡Œï¼Ÿ | å·´é» | model_b | å¸¸è¯† |

å…¶ä¸­â€œpromptâ€ åˆ—è¡¨ç¤ºè¾“å…¥é—®é¢˜ï¼Œè€Œ â€œoutputâ€ åˆ—ä»£è¡¨æ¨¡å‹çš„è¾“å‡ºã€‚æ­¤å¤–ï¼Œâ€œmodelâ€ åˆ—å¯¹åº”æ‰€ä½¿ç”¨çš„æ¨¡å‹çš„åç§°ï¼Œæœ€åï¼Œâ€œcategoryâ€ åˆ—è¡¨ç¤ºæ¯ä¸ªé—®é¢˜çš„ä»»åŠ¡ç±»å‹ã€‚

ä¸‹ä¸€æ­¥æ˜¯åˆ©ç”¨ GPT-4 æ¥è¯„ä¼°æˆ‘ä»¬æ¨¡å‹çš„é¢„æµ‹å¹¶ä¸ºæ¯ä¸ªç­”æ¡ˆæ‰“åˆ†ã€‚æˆ‘ä»¬é€‰æ‹©è¿™ç§æ–¹æ³•æ˜¯å› ä¸ºå½“å‰ç”±æŒ‡ä»¤å¾®è°ƒçš„è¯­è¨€æ¨¡å‹ç¼ºä¹é€‚å½“çš„è¯„ä¼°æŒ‡æ ‡ã€‚æ‰‹åŠ¨è¯„ä¼°æˆæœ¬é«˜æ˜‚ä¸”è€—æ—¶ï¼Œä¸é€‚ç”¨äºé¢‘ç¹çš„å®éªŒå’Œè¯„ä¼°ã€‚

è¦ä½¿ç”¨è‡ªåŠ¨è¯„ä¼°ï¼Œåªéœ€é€šè¿‡å‘½ä»¤è¡Œè¾“å…¥æ‚¨çš„æ–‡ä»¶å³å¯ã€‚

```bash
auto-eval file --config_file OPENAI_API_KEY_CONFIG_PATH \
--eval_data_path model_predictions.json \
--output_path eval_result_path.xlsx \
--model gpt-4 \
--interval 12 
```

Auto-Evalå°†æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š

æ­¥éª¤1ï¼šæ ¹æ®é—®é¢˜åˆ—ï¼ˆè¿™é‡Œå¯¹åº”â€œpromptâ€åˆ—ï¼‰å°†é—®é¢˜åˆ†ç»„ã€‚æ¯ç»„åŒ…å«ä¸€ä¸ªé—®é¢˜å’Œå¤šä¸ªæ¨¡å‹ç­”æ¡ˆã€‚

æ­¥éª¤2ï¼šç»„ç»‡è¯„ä¼°æç¤ºï¼Œå¸®åŠ©GPT-4ç†è§£å®ƒæ­£åœ¨è¯„ä¼°ä»»åŠ¡ï¼Œå¹¶ä¸ºæ¯ä¸ªç­”æ¡ˆè¾“å‡ºåˆ†æ•°ã€‚

æ­¥éª¤3ï¼šè¯„ä¼°æ‰€æœ‰é—®é¢˜å’Œç­”æ¡ˆåï¼Œå°†è¾“å‡ºå¾—åˆ†ç»“æœã€‚

è¯·æ³¨æ„ï¼Œå°½ç®¡æ­¤ç¤ºä¾‹ä»…ä½¿ç”¨ä¸€ä¸ªæ–‡ä»¶ï¼Œä½†æ‚¨ä¹Ÿå¯ä»¥ä½¿ç”¨å¤šä¸ªæ–‡ä»¶ï¼Œæ¯ä¸ªæ–‡ä»¶ä»£è¡¨ä¸€ä¸ªæ¨¡å‹çš„è¾“å‡ºã€‚

## å®‰è£…

```
pip install -U auto-eval

```

## è¯¦ç»†ä½¿ç”¨æ–¹æ³•

è¦ä½¿ç”¨æ­¤åº“ï¼Œæ‚¨å¿…é¡»é¦–å…ˆä»OpenAIã€Microsoft Azureæˆ–Anthropicè·å–APIå¯†é’¥ã€‚è¦è·å–OpenAI APIå¯†é’¥ï¼Œè¯·è®¿é—®å…¶ç½‘ç«™ https://platform.openai.com/account/api-keys ï¼Œå¯¹Antropic APIå¯†é’¥ï¼Œè¯·è½¬åˆ°Anthropicç½‘ç«™ https://console.anthropic.com/account/keysã€‚

æ­¤å¤–ï¼Œéœ€è¦é…ç½®APIçš„base urlã€‚å¦‚æœéœ€è¦ï¼Œå¯ä»¥æŒ‡å®šä»£ç†URLï¼Œä¾‹å¦‚ â€œhttps://your_proxy_domain/v1â€ã€‚å…³äºAzure APIçš„ç›¸å…³ä¿¡æ¯å¯ä»¥åœ¨Azureèµ„æºä»ªè¡¨æ¿ä¸Šæ‰¾åˆ°ï¼ŒAPIæ ¼å¼ä¸º â€œhttps://{your_organization}.openai.azure.com/â€ã€‚


### æ­¥éª¤1ï¼šåœ¨æœ¬åœ°é…ç½®æ–‡ä»¶ä¸­è®¾ç½®APIå¯†é’¥ä¿¡æ¯ã€‚

**OpenAI config:**
```json
{
    "api_key": "YOUR_API_KEY",
    "api_base": "https://api.openai.com/v1",
    "api_type": "open_ai"
}
```
**Azure OpenAI config:**
```json
{
    "api_key": "YOUR_API_KEY",
    "api_base": "Replace with your Azure OpenAI resource's endpoint value.",
    "api_type": "azure"
}
```
**Anthropic config:**
```json
{
    "api_key": "YOUR_API_KEY",
    "api_base": "https://api.anthropic.com",
    "api_type": "claude"
}
```
`api_type` å¯é€‰å€¼ä¸º "open_ai"ã€"azure" æˆ– "claude"ã€‚

### æ­¥éª¤2ï¼šä½¿ç”¨å‘½ä»¤è¡Œæ‰§è¡Œè¯„ä¼°ä»»åŠ¡

### è¯„ä¼°å•ä¸ªé—®ç­”
å¤šä¸ªå€™é€‰ç­”æ¡ˆç”¨ç©ºæ ¼åˆ†å‰²ï¼Œä¾‹å¦‚ "1 2 3 4"ã€‚å¦‚æœæ‚¨çš„ç­”æ¡ˆä¸­åŒ…å«ç©ºæ ¼ï¼Œè¯·ä½¿ç”¨åŒå¼•å·å°†å…¶æ‹¬èµ·æ¥ï¼Œä¾‹å¦‚ "1 2 3 4" "1 2 3 4"ã€‚


```sh
auto-eval line --config_file CHANGE_TO_YOUR_CONFIG_PATH \
--model gpt-3.5-turbo \
--prompt "4*5-10=?" \
--answers "4*5-10=20-10=40" -10 10 40 
```

<details> <summary>è¾“å‡º:</summary>

```text

Using prompt template:
{
    "eval_with_target_template": "Here is the question and candidate answers:\n\n ```text\n\n[Question]: \n{question}\n\n[Candidate answer]:\n\n{answers}\n\n```\n\n Please solve the question independently without referring to the candidate answers.\nThen evaluate each [Candidate answer] and provide a rating score between 0-1 along with your comments.\nFinally, output all [Candidate answers] scores in JSON format: {{\"number\": \"{{score}}\"}}.",
    "eval_without_target_template": "Here is the question and candidate answers:\n\n ```text\n\n[Question]: \n{question}\n\n[Candidate answer]:\n\n{answers}\n\n```\n\n Please solve the question independently without referring to the candidate answers.\nThen evaluate each [Candidate answer] and provide a rating score between 0-1 along with your comments.\nFinally, output all [Candidate answers] scores in JSON format: {{\"number\": \"{{score}}\"}}."
}

-------------------- prompt detail ğŸš€  --------------------

Here is the question and candidate answers:


[Question]: 
4*5-10=?

[Candidate answer]:

A. 4*5-10=20-10=40

B. -10

C. 10

D. 40

Please solve the question independently without referring to the candidate answers.
Then evaluate each [Candidate answer] and provide a rating score between 0-1 along with your comments.
Finally, output all [Candidate answers] scores in JSON format: {"number": "{score}"}.

-------------------- prompt end --------------------

-------------------- response detail â­ï¸ --------------------

Solution:

4*5-10=20-10=10

[Candidate answer]:

A. 4*5-10=20-10=40 - Incorrect, the calculation is incorrect.

B. -10 - Incorrect, the answer is not -10.

C. 10 - Correct, the answer is 10.

D. 40 - Incorrect, the calculation is incorrect.

{"A": "0", "B": "0", "C": "1", "D": "0"}

Comments: Only option C is correct. The other options either have incorrect calculations or incorrect answers.

-------------------- response end --------------------


SCORE:
[0.0, 0.0, 1.0, 0.0]
```

</details>


#### åŸºäºè¾“å…¥æ–‡ä»¶è¿›è¡Œè¯„ä¼°

```sh
auto-eval file --config_file CHANGE_TO_YOUR_CONFIG_PATH \
--eval_data_path model_a_pred.json model_b_pred.json model_c_pred.json \
--output_path eval_result_path.xlsx \
--model gpt-4 
```

**è¾“å…¥æ–‡ä»¶æ ¼å¼ï¼š**

- è¾“å…¥æ–‡ä»¶æ”¯æŒæ‰©å±•åä¸º .jsonã€.jsonlã€.csv å’Œ .xlsx çš„æ–‡ä»¶ã€‚
- è¦å¯¹å¤šä¸ªæ–‡ä»¶è¿›è¡Œæ¯”è¾ƒï¼Œè¯·ä½¿ç”¨å‚æ•° `eval_data_path`ï¼Œåé¢è·Ÿç€ç”¨ç©ºæ ¼åˆ†éš”çš„æ–‡ä»¶åã€‚ä¾‹å¦‚ï¼š`eval_data_path file1.json file2.json ... fileN.json`ã€‚æ–‡ä»¶å¯ä»¥å…·æœ‰ä¸åŒçš„æ ¼å¼ï¼Œåªè¦å®ƒä»¬éµå¾ªä¸‹é¢æåˆ°çš„å…¶ä¸­ä¸€ç§æ ¼å¼å³å¯ã€‚
ä¸ºäº†ç®€åŒ–ä¸åŒæ¨¡å‹çš„åˆ†æ•°æ¯”è¾ƒï¼Œå»ºè®®æ·»åŠ ä¸€ä¸ªâ€œmodelâ€åˆ—ï¼Œä»¥åŒºåˆ†ä¸åŒæ¨¡å‹çš„åç§°ï¼Œå¹¶ä½¿å¾—å¯ä»¥è½»æ¾è¾“å‡ºæ¥è‡ªå¤šä¸ªæ¨¡å‹çš„åˆ†æ•°ç»Ÿè®¡ä¿¡æ¯ã€‚
- è¦æŸ¥çœ‹æ›´è¯¦ç»†çš„å‚æ•°ï¼Œè¯·åœ¨å®‰è£…è¯¥å­˜å‚¨åº“åä½¿ç”¨å‘½ä»¤ `auto-eval file -h`ï¼Œæˆ–å‚è€ƒä¸‹é¢çš„å®Œæ•´æ–‡æ¡£ã€‚
- æ–‡ä»¶çš„è¡¨å¤´ï¼ˆåˆ—åï¼‰å¯ä»¥æ˜¯ä»¥ä¸‹ç±»å‹ä¹‹ä¸€ï¼š
    - `{"instruction", "input", "output"}`
    - `{"prompt", "output"}`
    - `{"question", "answer"}`
    - `{"question", "output"}`
    - `{"question", "target"}`

    "question"ã€"prompt" å’Œ "instruction" + "input" æŒ‡çš„æ˜¯è¾“å…¥é—®é¢˜ï¼Œä¾‹å¦‚ "è¯·ä»”ç»†è®¡ç®—ï¼š1+1=ï¼Ÿ" æˆ– "åƒæˆ‘ä¸€æ ·äº”å²çš„å­©å­è§£é‡Šç™»ä¸Šæœˆçƒ"ã€‚"answer" å’Œ "output" è¡¨ç¤ºç»™å®šé—®é¢˜çš„æ¨¡å‹çš„é¢„æµ‹ç­”æ¡ˆã€‚å¦‚æœæ ¼å¼ä¸º {"instruction", "input"}ï¼Œä¸¤ä¸ªå­—æ®µçš„å€¼ä¼šè¢«æ‹¼æ¥ä»¥åˆ›å»ºä¸€ä¸ªå®Œæ•´çš„é—®é¢˜ã€‚
    

ä»¥ä¸‹æ˜¯ä¸€ä¸ªJSONæ ¼å¼çš„æµ‹è¯•æ•°æ®ç¤ºä¾‹ï¼ŒåŒ…å«äº†æ¨¡å‹çš„ä¼ªé¢„æµ‹ï¼Œä»¥ä¾¿äº†è§£è¯„ä¼°è¾“å…¥æ–‡ä»¶çš„æ ·å­ã€‚


```
[
    {"category":"æ•°å­¦","instruction":"'æˆ‘æƒ³ä¿®ç†èŠ±å›­çš„å›´å¢™ã€‚å¸®æˆ‘ä¼°ç®—ä¸€ä¸‹éœ€è¦å‡†å¤‡å¤šå°‘å°ºé•¿çš„å›´å¢™ã€‚æˆ‘çš„èŠ±å›­å®½10ç±³ï¼Œé•¿5ç±³ï¼Œå…¶ä¸­ä¸€è¾¹é ç€å¢™ã€‚'", "input":"","output":"ç­”æ¡ˆæ˜¯15ç±³", "model": "æ¨¡å‹A"},
    {"category":"æ•°å­¦","instruction":"å°†è¿™ä¸ªæ•°å­—åˆ—è¡¨æŒ‰å‡åºæ’åº", "input": "[230, 1, 4, 7000, 20, 300]","output":"[1, 4, 230, 7000, 20, 300]", "model": "æ¨¡å‹A"},
    {"category":"æ•°å­¦","instruction":"å°†è¿™ä¸ªæ•°å­—åˆ—è¡¨æŒ‰é™åºæ’åº", "input":"[230ï¼Œ1ï¼Œ4ï¼Œ7000ï¼Œ20 ï¼Œ300]","output":"[7000, 300, 230, 20, 4, 1]", "model": "æ¨¡å‹A"}
]

```

**è¾“å‡ºæ–‡ä»¶æ ¼å¼:**

- è¾“å‡ºæ–‡ä»¶å¯ä»¥æŒ‡å®šä¸º .jsonã€.jsonlã€.csv æˆ– .xlsx æ‰©å±•åã€‚
- å¦‚æœè¾“å…¥æ–‡ä»¶åŒ…å«ä¸€ä¸ªåä¸ºâ€œmodelâ€çš„å­—æ®µï¼Œåˆ™å¾—åˆ†å’Œç»Ÿè®¡ä¿¡æ¯å°†æ ¹æ®æ­¤å­—æ®µè¿›è¡Œåˆ†ç»„ã€‚
- å¦‚æœè¾“å…¥æ–‡ä»¶è¿˜åŒ…å«åä¸ºâ€œmodelâ€å’Œâ€œcategoryâ€çš„å­—æ®µï¼Œåˆ™å¾—åˆ†å’Œç»Ÿè®¡ä¿¡æ¯å°†æ ¹æ®è¿™ä¸¤ä¸ªå­—æ®µè¿›è¡Œåˆ†ç»„ã€‚
- ä»»ä½•å…¶ä»–å­—æ®µéƒ½ä¸ä¼šè¢«å¤„ç†ï¼›è¾“å‡ºå°†åŒ…æ‹¬åŸå§‹è¾“å…¥çš„æ‰€æœ‰åˆ—ä»¥åŠè¯„ä¼°å¾—åˆ†å’Œè¯´æ˜ã€‚

<details open> <summary>è¾“å‡ºæ—¥å¿—:</summary>

å…¶ä¸­ï¼Œprompts and responses detail... éƒ¨åˆ†ä¸ºè¯¦ç»†çš„è¾“å‡ºå†…å®¹ã€‚

- ------------------ æ¨¡å‹å¾—åˆ†æƒ…å†µ --------------------

| æ¨¡å‹ | å¾—åˆ† |
| --- | --- |
| æ¨¡å‹A | 81.5/100 |
| æ¨¡å‹B | 91.3/100 |
| æ¨¡å‹C | 80.0/100 |
- ------------------ æ¨¡å‹å’Œä»»åŠ¡ç±»åˆ«å¾—åˆ†æƒ…å†µ --------------------

| æ¨¡å‹ | ä»»åŠ¡ç±»åˆ« | å¾—åˆ† |
| --- | --- | --- |
| æ¨¡å‹A | å¸¸è¯†é—®ç­” | 15.5/20 |
| æ¨¡å‹B | å¸¸è¯†é—®ç­” | 17.3/20 |
| æ¨¡å‹C | å¸¸è¯†é—®ç­” | 14.7/20 |
| æ¨¡å‹A | åˆç­‰ç®—æœ¯ | 10.0/15 |
| æ¨¡å‹B | åˆç­‰ç®—æœ¯ | 11.0/15 |
| æ¨¡å‹C | åˆç­‰ç®—æœ¯ | 9.2/15 |

</details>

## å‚æ•°å®šä¹‰ï¼š

### å…±äº«å‚æ•°

`--config_file` string ${\color{orange}\text{å¿…éœ€}}$ <br>
åŒ…å« API å¯†é’¥ä¿¡æ¯çš„æœ¬åœ°é…ç½®æ–‡ä»¶ã€‚

<span id="jump">`--template_path` string ${\color{grey}\text{å¯é€‰}}$
<br>æ¨¡æ¿æ–‡ä»¶è·¯å¾„åº”è¯¥æ˜¯ JSON æ ¼å¼çš„ï¼ŒæŒ‡ç¤ºæ¨¡å‹è¯„ä¼°å¹¶è¯„è®ºæ¯ä¸ªç­”æ¡ˆï¼Œä»¥åŠåœ¨ JSON æ ¼å¼ä¸­è¾“å‡ºæ‘˜è¦åˆ†æ•°ï¼Œä¾‹å¦‚ `{"A": 0, "B": 0.1}`ã€‚

å¦‚æœæ²¡æœ‰æŒ‡å®šæ¨¡æ¿ï¼Œå°†ä½¿ç”¨ä¸‹é¢çš„é»˜è®¤æ¨¡æ¿ã€‚

```python
EVAL_WITH_TARGET_TEMPLATE ="""
[Question]: {question}

[Correct answer]: {target}

[Candidate answer]:

{answers}

[System]:
Please evaluate and comment each [Candidate answer] based on the [Correct answer].
Then output all [Candidate answer] scores (0-1) in a summary format of
{{\"number\": \"score\"}}, e.g, {{\"A\": \"0.2\", \"B\": \"0.8\"}}.
"""

EVAL_WITHOUT_TARGET_TEMPLATE = """
[Question]: {question}

[Candidate answer]: 
{answers}

[System]:
Please solve the [Question] independently to obtain the [Correct answer].
Then evaluate and comment each [Candidate answer] based on the [Correct answer].
Finally, output all [Candidate answers] scores (0-1) in a summary format of
{{\"number\": \"score\"}}, e.g, {{\"A\": \"0.2\", \"B\": \"0.8\"}}.
"""
```



å¦‚æœæ‚¨æƒ³ä½¿ç”¨è‡ªå®šä¹‰æ¨¡æ¿ï¼Œè¯·ç¡®ä¿å®ƒå…·æœ‰â€œquestionâ€ã€â€œanswersâ€çš„æ’æ§½ã€‚â€œtargetâ€åªæœ‰åœ¨æ‚¨çš„è¯„ä¼°æ•°æ®å…·æœ‰åä¸ºâ€œtargetâ€çš„åˆ—æ—¶æ‰æ˜¯å¿…éœ€çš„ã€‚

```json
{
    "eval_with_target_template": "[Question]: {question}\n\n[Correct answer]: {target}\n\n[Candidate answer]:\n{answers}\n\n[System]:\nPlease solve the [Question] independently to obtain the [Correct answer], and then evaluate and comment each [Candidate answer] based on the [Correct answer]. Finally, output all [Candidate answers] scores (0-1) in a summary format of {{\"number\": \"score\"}}, e.g, {{\"A\": \"0.2\", \"B\": \"0.8\"}}",
    "eval_without_target_template": "[Question]: {question}\n\n[Candidate answer]:\n{answers}\n\n[System]:\nPlease evaluate and comment each [Candidate answer] based on the [Correct answer]. Then output all [Candidate answer] scores (0-1) in a summary format of {{\"number\": \"score\"}}, e.g, {{\"A\": \"0.2\", \"B\": \"0.8\"}}" 
}

```



`--template_type` string ${\color{grey}\text{å¯é€‰}}$ é»˜è®¤ä¸º null

ç”¨äºè¯„ä¼°çš„æ¨¡æ¿ã€‚é»˜è®¤æ¨¡æ¿å¦‚ä¸Šæ‰€ç¤ºã€‚å¦ä¸€ä¸ªå¯é€‰æ¨¡æ¿ç‰¹å®šäºç”µå­å•†åŠ¡é¢†åŸŸã€‚è¦ä½¿ç”¨å®ƒï¼Œè¯·ä¼ é€’â€œ-template_type e_commerceâ€ã€‚

`--verbose` bool ${\color{grey}\text{å¯é€‰}}$ é»˜è®¤ä¸º True


æ˜¯å¦æ‰“å°æ¯ä¸ªæç¤ºå’Œå“åº”çš„è¯¦ç»†ä¿¡æ¯ã€‚
`--model` string ${\color{grey}\text{å¯é€‰}}$ é»˜è®¤ä¸º gpt-3.5-turbo æˆ– claude-v1.3 å–å†³äº `api_type`

è¦æ‰§è¡Œè¯„ä¼°ä»»åŠ¡çš„æ¨¡å‹æ˜¯å“ªä¸ªã€‚é»˜è®¤è¯„ä¼°æ¨¡å‹ä¸º gpt-3.5-turbo æˆ– claude-v1.3ï¼Œå…·ä½“å–å†³äº API ç±»å‹ã€‚æ‚¨å¯ä»¥æŒ‡å®šè¦ç”¨äºè¯„ä¼°çš„æ¨¡å‹çš„åç§°ï¼Œä¾‹å¦‚â€œgpt-4â€ã€â€œclaude-instant-v1â€æˆ–â€œclaude-v1.3â€ã€‚

`--temperature` number ${\color{grey}\text{å¯é€‰}}$ é»˜è®¤ä¸º 1

ä½¿ç”¨å“ªä¸ªé‡‡æ ·æ¸©åº¦ã€‚æ›´é«˜çš„å€¼ï¼ˆä¾‹å¦‚1ï¼‰ä¼šä½¿è¾“å‡ºæ›´éšæœºï¼Œè€Œè¾ƒä½çš„å€¼ï¼ˆä¾‹å¦‚0.1ï¼‰ä¼šä½¿å…¶æ›´åŠ é›†ä¸­å’Œç¡®å®šæ€§ã€‚

`--max_new_tokens` number ${\color{grey}\text{å¯é€‰}}$ é»˜è®¤ä¸º 2048

ç”Ÿæˆçš„æœ€å¤§å­—ç¬¦æ•°ã€‚æ¨¡å‹çš„ä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶äº†è¾“å…¥è¾“å‡ºçš„æ€»é•¿åº¦ã€‚

### è¯„ä¼°ä¸€ä¸ªæ ·æœ¬çš„å‚æ•°

`--prompt` string ${\color{orange}\text{å¿…éœ€}}$

é—®é¢˜ï¼Œä¾‹å¦‚ä¸€ä¸ªæ•°å­¦é—®é¢˜å¯èƒ½æ˜¯è¿™æ ·çš„: "1+1=?"ã€‚

`--answers` array ${\color{orange}\text{å¿…éœ€}}$

é—®é¢˜çš„å€™é€‰ç­”æ¡ˆï¼Œç­”æ¡ˆå¿…é¡»ç”¨ç©ºæ ¼åˆ†éš”ã€‚ä¾‹å¦‚ï¼Œä¸€ç»„å››ä¸ªç­”æ¡ˆçœ‹èµ·æ¥åƒè¿™æ ·: 1 0 -1 2

`--target` string ${\color{grey}\text{å¯é€‰}}$ é»˜è®¤ä¸º null

é—®é¢˜çš„æ­£ç¡®ç­”æ¡ˆã€‚æç¤ºå°†æ ¹æ®æ˜¯å¦æä¾›ç­”æ¡ˆè€Œä¸åŒï¼Œä¾‹å¦‚ï¼Œå¦‚æœæ²¡æœ‰æä¾›ç­”æ¡ˆï¼Œå°†è¦æ±‚æ¨¡å‹å…ˆè§£å†³é—®é¢˜ï¼Œç„¶åæ ¹æ®æ­£ç¡®ç­”æ¡ˆè¯„ä¼°æ¯ä¸ªå€™é€‰ç­”æ¡ˆã€‚

### è¯„ä¼°æ–‡ä»¶çš„å‚æ•°

`--eval_data_path`: string ${\color{orange}\text{å¿…éœ€}}$

è¿™æ˜¯è¦è¯„ä¼°çš„è¾“å…¥æ•°æ®çš„æ–‡ä»¶è·¯å¾„ã€‚å¦‚æœæä¾›äº†å¤šä¸ªæ–‡ä»¶ï¼Œè¯·ç¡®ä¿å®ƒä»¬å…·æœ‰ç›¸åŒçš„åˆ—åç§°ã€‚

`--output_path`: string ${\color{orange}\text{å¿…éœ€}}$

è¯„ä¼°ç»“æœçš„è¾“å‡ºæ–‡ä»¶è·¯å¾„ã€‚

`--eval_categories`: array ${\color{grey}\text{å¯é€‰}}$ é»˜è®¤ä¸º null

é€‰æ‹©è¦è¯„ä¼°çš„ç‰¹å®šé—®é¢˜ç±»åˆ«ç±»å‹ã€‚ä»…å½“è¾“å…¥æ–‡ä»¶åŒ…å«ä¸æ¯ä¸ªé—®é¢˜å¯¹åº”çš„â€œcategoryâ€åˆ—æ—¶ï¼Œæ­¤é€‰é¡¹æ‰æœ‰æ•ˆã€‚

`--question_column_names`: array ${\color{grey}\text{å¯é€‰}}$ é»˜è®¤ä¸º null

æŒ‡å®šç‰¹å®šåˆ—ä½œä¸ºé—®é¢˜åˆ—ã€‚å¦‚æœæŒ‡å®šäº†å¤šä¸ªåˆ—ï¼Œåˆ™è¿™äº›åˆ—å°†ä¸æ¢è¡Œç¬¦`\n`è¿æ¥èµ·æ¥å½¢æˆå®Œæ•´çš„é—®é¢˜åˆ—ã€‚

`--answer_column_names`: array ${\color{grey}\text{å¯é€‰}}$ é»˜è®¤ä¸º null

æŒ‡å®šç‰¹å®šåˆ—ä½œä¸ºç­”æ¡ˆåˆ—ã€‚å¦‚æœæŒ‡å®šäº†å¤šä¸ªåˆ—ï¼Œåˆ™è¿™äº›åˆ—å°†ä¸ `\n` è¿æ¥èµ·æ¥å½¢æˆå®Œæ•´çš„ç­”æ¡ˆåˆ—ã€‚

`--sample_num`: number ${\color{grey}\text{å¯é€‰}}$ é»˜è®¤ä¸º 0

é‡‡æ ·è¦è¯„ä¼°æ ·æœ¬æ•°é‡ï¼Œæç¤º+å„ä¸ªæ¨¡å‹ç­”æ¡ˆç»„æˆä¸€ä¸ªæ ·æœ¬ã€‚

`--interval`: number ${\color{grey}\text{å¯é€‰}}$ é»˜è®¤ä¸º 1

æ¯æ¬¡è¯·æ±‚ä¹‹é—´çš„ç¡çœ é—´éš”ï¼ˆä»¥ç§’ä¸ºå•ä½ï¼‰ï¼Œä»¥é¿å…è¶…è¿‡è¯·æ±‚é€Ÿç‡é™åˆ¶ã€‚å»ºè®®ä¸º GPT-4 ä½¿ç”¨è¾ƒå¤§çš„å€¼ï¼Œä¾‹å¦‚ `--interval 10`ã€‚

`--retry`: ${\color{grey}\text{å¯é€‰}}$ é»˜è®¤ä¸º True

æ˜¯å¦å¯¹æ‰€æœ‰å¤±è´¥çš„è¯·æ±‚é‡è¯•ä¸€æ¬¡ã€‚å¤±è´¥çš„è¯·æ±‚å¯èƒ½æ˜¯ç”±äºè¶…å‡º API è¯·æ±‚é¢‘ç‡ã€é”™è¯¯çš„ç­”æ¡ˆæ ¼å¼è§£ææˆ–ç½‘ç»œæ•…éšœç­‰åŸå› è€Œå¯¼è‡´çš„ã€‚

`--score_by`: array ${\color{grey}\text{å¯é€‰}}$ é»˜è®¤ä¸º null

ç”¨äºç¡®å®šç”¨äº `pandas.groupby(by=args.score_by)` è¿›è¡Œ groupby åˆ†ç»„çš„å­—æ®µã€‚

## å¾…å®Œæˆäº‹é¡¹

- [ ]  å°†å¤šä¸ª GPT ç±»ä¼¼çš„æ¨¡å‹ç»„åˆè¿›è¡Œé¢„æµ‹: è·¯ç”±æˆ–ç®€å•å¹³å‡ã€‚
- [x]  æ”¯æŒæç¤ºè¯„ä¼°ï¼Œè¾“å‡ºä¸åŒæç¤ºçš„å‡†ç¡®æ€§ã€‚
- [ ]  ä¸ºæç¤ºè¯„ä¼°é…ç½®é»˜è®¤æµ‹è¯•é›†ã€‚